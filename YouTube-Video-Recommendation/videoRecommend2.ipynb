{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsLKGaqsbfimxBlb1euqa0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PoojaDD-18/EnglishToFrenchTranslation/blob/main/YouTube-Video-Recommendation/videoRecommend2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "API_KEY = os.environ.get(\"AIzaSyAtTRGo1r2Lpy8Tfzz9tfCAz2kUx4LgX9c\")\n",
        "MAX_SEARCH_RESULTS = 50\n",
        "TOP_N = 10\n",
        "MIN_VIEW_COUNT = 1000\n",
        "RELEVANCE_LANGUAGE = \"en\"\n",
        "RECENCY_BOOST_DAYS = 30\n",
        "RECENCY_BOOST_FACTOR = 0.1\n",
        "\n",
        "def calculate_engagement_rate(likes, comments, views):\n",
        "    return (likes + comments) / views if views else 0\n",
        "\n",
        "def calculate_recency_factor(published_at):\n",
        "    published_date = datetime.strptime(published_at[:10], '%Y-%m-%d').date()\n",
        "    age = (datetime.now().date() - published_date).days\n",
        "    return RECENCY_BOOST_FACTOR if age <= RECENCY_BOOST_DAYS else 0\n",
        "\n",
        "def normalize_data(data):\n",
        "    if not data:\n",
        "        return []\n",
        "    scaler = MinMaxScaler()\n",
        "    return [x[0] for x in scaler.fit_transform([[v] for v in data])]\n",
        "\n",
        "def search_youtube_videos(youtube, topic, max_results=MAX_SEARCH_RESULTS):\n",
        "    try:\n",
        "        resp = youtube.search().list(\n",
        "            q=topic, type=\"video\", maxResults=max_results,\n",
        "            part=\"snippet\", relevanceLanguage=RELEVANCE_LANGUAGE, order=\"relevance\"\n",
        "        ).execute()\n",
        "        return [item['id']['videoId'] for item in resp.get('items', [])]\n",
        "    except HttpError as e:\n",
        "        print(f\"HTTP Error {e.resp.status}: {e.content}\")\n",
        "        return []\n",
        "\n",
        "def fetch_video_stats(youtube, video_ids):\n",
        "    try:\n",
        "        resp = youtube.videos().list(\n",
        "            id=','.join(video_ids), part=\"statistics,snippet,contentDetails\"\n",
        "        ).execute()\n",
        "        videos = {}\n",
        "        for item in resp.get('items', []):\n",
        "            stats = item.get('statistics', {})\n",
        "            snippet = item.get('snippet', {})\n",
        "            cd = item.get('contentDetails', {})\n",
        "            videos[item['id']] = {\n",
        "                'title': snippet.get('title', ''),\n",
        "                'channelName': snippet.get('channelTitle', ''),\n",
        "                'viewCount': int(stats.get('viewCount', 0) or 0),\n",
        "                'likeCount': int(stats.get('likeCount', 0) or 0),\n",
        "                'commentCount': int(stats.get('commentCount', 0) or 0),\n",
        "                'publishedAt': snippet.get('publishedAt', ''),\n",
        "                'hasEnglishCaptions': cd.get('caption') == 'true'\n",
        "            }\n",
        "        return videos\n",
        "    except HttpError as e:\n",
        "        print(f\"HTTP Error {e.resp.status}: {e.content}\")\n",
        "        return {}\n",
        "\n",
        "def rank_videos(videos_data):\n",
        "    view_counts = [v['viewCount'] for v in videos_data.values()]\n",
        "    like_counts = [v['likeCount'] for v in videos_data.values()]\n",
        "    norm_views = normalize_data(view_counts)\n",
        "    norm_likes = normalize_data(like_counts)\n",
        "\n",
        "    ranked = []\n",
        "    for (vid, data), nv, nl in zip(videos_data.items(), norm_views, norm_likes):\n",
        "        if data['viewCount'] >= MIN_VIEW_COUNT:\n",
        "            score = (\n",
        "                0.4 * nv +\n",
        "                0.2 * nl +\n",
        "                0.2 * calculate_engagement_rate(data['likeCount'], data['commentCount'], data['viewCount']) +\n",
        "                0.2 * calculate_recency_factor(data['publishedAt'])\n",
        "            )\n",
        "            ranked.append({**data, 'videoId': vid, 'score': score})\n",
        "    return sorted(ranked, key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "def output_top_videos(ranked, top_n=TOP_N):\n",
        "    print(f\"\\n--- Top {top_n} Ranked Videos ---\")\n",
        "    for i, v in enumerate(ranked[:top_n]):\n",
        "        print(f\"\\nRank {i+1}:\")\n",
        "        print(f\"  Title: {v['title']}\")\n",
        "        print(f\"  Channel: {v['channelName']}\")\n",
        "        print(f\"  Views: {v['viewCount']:,}\")\n",
        "        print(f\"  Likes: {v['likeCount']:,}\")\n",
        "        print(f\"  Engagement Rate: {calculate_engagement_rate(v['likeCount'], v['commentCount'], v['viewCount']):.4f}\")\n",
        "        print(f\"  URL: https://www.youtube.com/watch?v={v['videoId']}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    topic = input(\"Enter search topic: \")\n",
        "    if not API_KEY:\n",
        "        print(\"Error: API key not set in environment variable YOUTUBE_API_KEY.\")\n",
        "    else:\n",
        "        yt = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "        vids = search_youtube_videos(yt, topic)\n",
        "        if vids:\n",
        "            stats = fetch_video_stats(yt, vids)\n",
        "            ranked = rank_videos(stats)\n",
        "            output_top_videos(ranked)\n",
        "        else:\n",
        "            print(\"No videos found.\")\n"
      ],
      "metadata": {
        "id": "1xW2CuWQdbnG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}